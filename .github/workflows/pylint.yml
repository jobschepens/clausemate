name: Comprehensive Testing

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false  # Don't cancel other jobs if one fails
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]
        python-version: ["3.11"]

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install nox

    - name: Run CI pipeline
      run: nox -s ci --python ${{ matrix.python-version }}

    - name: Upload coverage to Codecov
      if: matrix.os == 'ubuntu-latest' && matrix.python-version == '3.11'
      uses: codecov/codecov-action@v3
      with:
        token: ${{ secrets.CODECOV_TOKEN }}
        file: ./coverage.xml

  reproducibility:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4

    - name: Set up Python 3.11
      uses: actions/setup-python@v4
      with:
        python-version: "3.11"

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -e ".[dev,benchmark]"

    - name: Test reproducibility
      run: |
        # Check if test data exists
        if [ -f "data/input/gotofiles/2.tsv" ]; then
          echo "Running reproducibility test with available data..."
          # Run Phase 2 twice and compare outputs using tracked test data
          python src/main.py data/input/gotofiles/2.tsv -o run1.csv
          python src/main.py data/input/gotofiles/2.tsv -o run2.csv

          # Check if outputs are identical
          if ! diff -q run1.csv run2.csv > /dev/null; then
            echo "ERROR: Phase 2 outputs are not reproducible"
            echo "Differences found:"
            diff run1.csv run2.csv || true
            exit 1
          else
            echo "SUCCESS: Phase 2 outputs are reproducible"
          fi
        else
          echo "⚠️ Test data not available, skipping reproducibility test"
          echo "✅ Reproducibility test skipped (no test data)"
        fi

    - name: Performance benchmarking
      run: |
        # memory-profiler and psutil are already installed via benchmark dependencies
        # Add basic performance tests using tracked test data
        python -c "
        import os
        import time
        import subprocess

        if os.path.exists('data/input/gotofiles/2.tsv'):
            print('Running performance benchmark with available data...')
            start = time.time()
            result = subprocess.run(['python', 'src/main.py', 'data/input/gotofiles/2.tsv', '-o', 'benchmark.csv'], capture_output=True)
            end = time.time()
            print(f'Phase 2 execution time: {end-start:.2f} seconds')
            if end-start > 30:  # Fail if takes more than 30 seconds
                print('⚠️ Performance test failed: execution time exceeded 30 seconds')
                exit(1)
            else:
                print('✅ Performance benchmark completed successfully')
        else:
            print('⚠️ Test data not available, skipping performance benchmark')
            print('✅ Performance benchmark skipped (no test data)')
        "
