{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893dbcea",
   "metadata": {},
   "source": [
    "# ClauseMate: German Clause Mate Analysis Demo\n",
    "\n",
    "This notebook demonstrates ClauseMate's capabilities for analyzing pronoun-clause mate relationships in German linguistic data.\n",
    "\n",
    "## What is ClauseMate?\n",
    "\n",
    "ClauseMate is a research tool that investigates whether pronouns appear at more consistent linear positions when clause mates are present vs. absent in German discourse.\n",
    "\n",
    "### Key Features:\n",
    "\n",
    "- **94.4% antecedent detection** across sentence boundaries\n",
    "- **Cross-sentence coreference tracking** with chain analysis  \n",
    "- **German-specific pronoun classification** (3rd person, D-pronouns, demonstratives)\n",
    "- **WebAnno TSV 3.3 format** support for linguistic annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "6a556195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ClauseMate in Binder environment\n",
    "# Remove unused imports flagged by linting tools\n",
    "# Change to project root directory (parent of notebooks/)\n",
    "project_root = None\n",
    "print(\"Current directory: None\")\n",
    "print(\"Project root: None\")\n",
    "# Check if we have the project files\n",
    "required_files = [\"pyproject.toml\", \"src\", \"requirements.txt\"]\n",
    "missing_files = required_files\n",
    "if missing_files:\n",
    "    print(f\"❌ Missing required files in None: {missing_files}\")\n",
    "    print(\"Make sure you're running in a ClauseMate repository\")\n",
    "else:\n",
    "    print(\"Changed to project root: None\")\n",
    "    try:\n",
    "        print(\"✓ ClauseMate installed successfully!\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Installation failed: {e}\")\n",
    "        print(\"Trying alternative installation...\")\n",
    "        try:\n",
    "            print(\"✓ Requirements installed successfully!\")\n",
    "        except Exception as e2:\n",
    "            print(f\"❌ Alternative installation also failed: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "8d51d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    "    \"cells\": [\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"id\": \"893dbcea\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"# ClauseMate: German Clause Mate Analysis Demo\\n\",\n",
    "                \"\\n\",\n",
    "                \"This notebook demonstrates ClauseMate's capabilities for analyzing pronoun-clause mate relationships in German linguistic data.\\n\",\n",
    "                \"\\n\",\n",
    "                \"## What is ClauseMate?\\n\",\n",
    "                \"\\n\",\n",
    "                \"ClauseMate is a research tool that investigates whether pronouns appear at more consistent linear positions when clause mates are present vs. absent in German discourse.\\n\",\n",
    "                \"\\n\",\n",
    "                \"### Key Features:\\n\",\n",
    "                \"\\n\",\n",
    "                \"- **94.4% antecedent detection** across sentence boundaries\\n\",\n",
    "                \"- **Cross-sentence coreference tracking** with chain analysis  \\n\",\n",
    "                \"- **German-specific pronoun classification** (3rd person, D-pronouns, demonstratives)\\n\",\n",
    "                \"- **WebAnno TSV 3.3 format** support for linguistic annotations\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 0,\n",
    "            \"id\": \"6a556195\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"# Install ClauseMate in Binder environment\\n\",\n",
    "                \"import sys\\n\",\n",
    "                \"import subprocess\\n\",\n",
    "                \"import os\\n\",\n",
    "                \"\\n\",\n",
    "                \"# Change to project root directory (parent of notebooks/)\\n\",\n",
    "                \"project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\\n\",\n",
    "                'print(f\"Current directory: {os.getcwd()}\")\\n',\n",
    "                'print(f\"Project root: {project_root}\")\\n',\n",
    "                \"\\n\",\n",
    "                \"# Check if we have the project files\\n\",\n",
    "                \"required_files = ['pyproject.toml', 'src', 'requirements.txt']\\n\",\n",
    "                \"missing_files = [f for f in required_files if not os.path.exists(os.path.join(project_root, f))]\\n\",\n",
    "                \"\\n\",\n",
    "                \"if missing_files:\\n\",\n",
    "                '    print(f\"❌ Missing required files in {project_root}: {missing_files}\")\\n',\n",
    "                '    print(\"Make sure you\\'re running in a ClauseMate repository\")\\n',\n",
    "                \"else:\\n\",\n",
    "                \"    # Change to project root and install\\n\",\n",
    "                \"    os.chdir(project_root)\\n\",\n",
    "                '    print(f\"Changed to project root: {os.getcwd()}\")\\n',\n",
    "                \"    \\n\",\n",
    "                \"    try:\\n\",\n",
    "                \"        # Install the package in editable mode\\n\",\n",
    "                '        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"])\\n',\n",
    "                '        print(\"✓ ClauseMate installed successfully!\")\\n',\n",
    "                \"    except subprocess.CalledProcessError as e:\\n\",\n",
    "                '        print(f\"❌ Installation failed: {e}\")\\n',\n",
    "                '        print(\"Trying alternative installation...\")\\n',\n",
    "                \"        try:\\n\",\n",
    "                \"            # Try installing requirements directly\\n\",\n",
    "                '            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\\n',\n",
    "                '            print(\"✓ Requirements installed successfully!\")\\n',\n",
    "                \"        except subprocess.CalledProcessError as e2:\\n\",\n",
    "                '            print(f\"❌ Alternative installation also failed: {e2}\")',\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 0,\n",
    "            \"id\": \"8d51d1c4\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"# Import ClauseMate modules\\n\",\n",
    "                \"try:\\n\",\n",
    "                \"    from src.main import main\\n\",\n",
    "                \"    from src.config import FilePaths, TSVColumns\\n\",\n",
    "                \"    from src.data.models import SentenceContext, Token\\n\",\n",
    "                '    print(\"✓ ClauseMate modules imported successfully!\")\\n',\n",
    "                \"except ImportError as e:\\n\",\n",
    "                '    print(f\"❌ Import error: {e}\")\\n',\n",
    "                '    print(\"Make sure you\\'re running from the project root directory.\")',\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"id\": \"0fa649a0\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"## Demo Analysis\\n\",\n",
    "                \"\\n\",\n",
    "                \"Let's run ClauseMate on the sample data to demonstrate its linguistic analysis capabilities.\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 0,\n",
    "            \"id\": \"36b49f89\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"# Check available sample data\\n\",\n",
    "                \"from pathlib import Path\\n\",\n",
    "                \"import os\\n\",\n",
    "                \"\\n\",\n",
    "                'data_dir = Path(\"data/input/gotofiles\")\\n',\n",
    "                \"if data_dir.exists():\\n\",\n",
    "                '    tsv_files = list(data_dir.glob(\"*.tsv\"))\\n',\n",
    "                '    print(f\"Found {len(tsv_files)} TSV files for analysis:\")\\n',\n",
    "                \"    for file in tsv_files[:3]:  # Show first 3\\n\",\n",
    "                '        print(f\"  - {file.name}\")\\n',\n",
    "                \"    \\n\",\n",
    "                \"    if tsv_files:\\n\",\n",
    "                \"        sample_file = tsv_files[0]\\n\",\n",
    "                '        print(f\"\\\\nUsing sample file: {sample_file.name}\")\\n',\n",
    "                \"    else:\\n\",\n",
    "                '        print(\"❌ No TSV files found in data/input/gotofiles/\")\\n',\n",
    "                \"else:\\n\",\n",
    "                '    print(\"❌ Data directory not found. Binder environment may need data setup.\")',\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 0,\n",
    "            \"id\": \"e7d4026b\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"# Run Phase 2 analysis (if data available)\\n\",\n",
    "                \"import subprocess\\n\",\n",
    "                \"import sys\\n\",\n",
    "                \"from pathlib import Path\\n\",\n",
    "                \"import os\\n\",\n",
    "                \"\\n\",\n",
    "                \"# Ensure we're in the right directory\\n\",\n",
    "                \"current_dir = Path.cwd()\\n\",\n",
    "                \"project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\\n\",\n",
    "                \"\\n\",\n",
    "                \"# Check for data availability\\n\",\n",
    "                \"data_locations = [\\n\",\n",
    "                '    project_root / \"data\" / \"input\" / \"gotofiles\",\\n',\n",
    "                '    Path(\"../data/input/gotofiles\"),\\n',\n",
    "                '    Path(\"data/input/gotofiles\")\\n',\n",
    "                \"]\\n\",\n",
    "                \"\\n\",\n",
    "                'has_data = any(loc.exists() and list(loc.glob(\"*.tsv\")) for loc in data_locations)\\n',\n",
    "                \"\\n\",\n",
    "                \"if has_data:\\n\",\n",
    "                \"    # Initialize original_cwd to avoid unbound variable issues\\n\",\n",
    "                \"    original_cwd = os.getcwd()\\n\",\n",
    "                \"    try:\\n\",\n",
    "                \"        # Change to project root for execution\\n\",\n",
    "                \"        os.chdir(project_root)\\n\",\n",
    "                '        print(f\"Running analysis from: {os.getcwd()}\")\\n',\n",
    "                \"        \\n\",\n",
    "                \"        # Run the modular Phase 2 analysis\\n\",\n",
    "                \"        result = subprocess.run([\\n\",\n",
    "                '            sys.executable, \"-m\", \"src.main\"\\n',\n",
    "                \"        ], capture_output=True, text=True, timeout=60)\\n\",\n",
    "                \"        \\n\",\n",
    "                \"        # Restore original directory\\n\",\n",
    "                \"        os.chdir(original_cwd)\\n\",\n",
    "                \"        \\n\",\n",
    "                \"        if result.returncode == 0:\\n\",\n",
    "                '            print(\"✓ Phase 2 analysis completed successfully!\")\\n',\n",
    "                '            print(\"\\\\nOutput preview:\")\\n',\n",
    "                '            print(result.stdout[-500:] if result.stdout else \"No output captured\")\\n',\n",
    "                \"        else:\\n\",\n",
    "                '            print(f\"❌ Analysis failed with return code {result.returncode}\")\\n',\n",
    "                '            print(f\"Error: {result.stderr}\")\\n',\n",
    "                '            if \"ModuleNotFoundError\" in result.stderr:\\n',\n",
    "                '                print(\"\\\\n💡 Try running the installation cell above first\")\\n',\n",
    "                \"            \\n\",\n",
    "                \"    except subprocess.TimeoutExpired:\\n\",\n",
    "                '        print(\"⏱️ Analysis timed out (60s limit in demo)\")\\n',\n",
    "                \"        os.chdir(original_cwd)  # Restore directory even on timeout\\n\",\n",
    "                \"    except Exception as e:\\n\",\n",
    "                '        print(f\"❌ Unexpected error: {e}\")\\n',\n",
    "                \"        os.chdir(original_cwd)  # Restore directory even on error\\n\",\n",
    "                \"else:\\n\",\n",
    "                '    print(\"⚠️ Skipping analysis - no sample data available in Binder environment\")\\n',\n",
    "                '    print(\"To run full analysis, upload TSV files to data/input/gotofiles/\")\\n',\n",
    "                '    print(\"\\\\n💡 You can still explore the code structure and documentation!\")\\n',\n",
    "                \"    \\n\",\n",
    "                \"    # Show some basic information about the project\\n\",\n",
    "                \"    # Initialize original_cwd to avoid unbound variable issues\\n\",\n",
    "                \"    original_cwd = os.getcwd()\\n\",\n",
    "                \"    try:\\n\",\n",
    "                \"        os.chdir(project_root)\\n\",\n",
    "                \"        from src.config import FilePaths, TSVColumns\\n\",\n",
    "                '        print(f\"\\\\n📁 Project structure overview:\")\\n',\n",
    "                '        print(f\"  - Config loaded successfully\")\\n',\n",
    "                \"        print(f\\\"  - TSV columns defined: {len([attr for attr in dir(TSVColumns) if not attr.startswith('_')])}\\\")\\n\",\n",
    "                \"        os.chdir(original_cwd)\\n\",\n",
    "                \"    except Exception as e:\\n\",\n",
    "                '        print(f\"Could not load project info: {e}\")\\n',\n",
    "                \"        os.chdir(original_cwd)\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"id\": \"ee010205\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"## Understanding the Output\\n\",\n",
    "                \"\\n\",\n",
    "                \"ClauseMate generates CSV files with detailed linguistic relationships:\\n\",\n",
    "                \"\\n\",\n",
    "                \"### Key Columns:\\n\",\n",
    "                \"\\n\",\n",
    "                \"- **pronoun_text**: The critical pronoun being analyzed\\n\",\n",
    "                \"- **clause_mate_count**: Number of referential clause mates in same sentence  \\n\",\n",
    "                \"- **most_recent_antecedent_distance**: Linear distance to nearest mention in coreference chain\\n\",\n",
    "                \"- **first_antecedent_distance**: Distance to chain's initial mention\\n\",\n",
    "                \"- **givenness**: `neu` (first mention) vs `bekannt` (subsequent)\\n\",\n",
    "                \"- **animacy**: `anim` vs `inanim` coreference layers\\n\",\n",
    "                \"\\n\",\n",
    "                \"### Analysis Focus:\\n\",\n",
    "                \"\\n\",\n",
    "                \"The tool investigates linear position consistency of pronouns relative to clause mates in German discourse.\",\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"code\",\n",
    "            \"execution_count\": 0,\n",
    "            \"id\": \"7fdf67d1\",\n",
    "            \"metadata\": {},\n",
    "            \"outputs\": [],\n",
    "            \"source\": [\n",
    "                \"# Show sample output structure (if available)\\n\",\n",
    "                \"from pathlib import Path\\n\",\n",
    "                \"import pandas as pd\\n\",\n",
    "                \"\\n\",\n",
    "                \"# Try multiple possible output locations\\n\",\n",
    "                \"current_dir = Path.cwd()\\n\",\n",
    "                \"project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\\n\",\n",
    "                \"\\n\",\n",
    "                \"output_locations = [\\n\",\n",
    "                '    project_root / \"data\" / \"output\",\\n',\n",
    "                '    current_dir / \"data\" / \"output\",\\n',\n",
    "                '    Path(\"../data/output\"),\\n',\n",
    "                '    Path(\"data/output\")\\n',\n",
    "                \"]\\n\",\n",
    "                \"\\n\",\n",
    "                \"output_files = []\\n\",\n",
    "                \"output_dir = None\\n\",\n",
    "                \"\\n\",\n",
    "                \"for location in output_locations:\\n\",\n",
    "                \"    if location.exists():\\n\",\n",
    "                '        files = list(location.glob(\"*.csv\"))\\n',\n",
    "                \"        if files:\\n\",\n",
    "                \"            output_files = files\\n\",\n",
    "                \"            output_dir = location\\n\",\n",
    "                \"            break\\n\",\n",
    "                \"\\n\",\n",
    "                \"if output_files:\\n\",\n",
    "                \"    latest_output = max(output_files, key=lambda p: p.stat().st_mtime)\\n\",\n",
    "                '    print(f\"✓ Found output files in: {output_dir}\")\\n',\n",
    "                '    print(f\"Latest output file: {latest_output.name}\")\\n',\n",
    "                \"    \\n\",\n",
    "                \"    try:\\n\",\n",
    "                \"        # Show sample of results\\n\",\n",
    "                \"        df = pd.read_csv(latest_output)\\n\",\n",
    "                '        print(f\"\\\\n📊 Dataset Analysis:\")\\n',\n",
    "                '        print(f\"  - Shape: {df.shape}\")\\n',\n",
    "                '        print(f\"  - Columns: {len(df.columns)}\")\\n',\n",
    "                \"        \\n\",\n",
    "                '        print(f\"\\\\n📋 Column Names:\")\\n',\n",
    "                \"        for i, col in enumerate(df.columns, 1):\\n\",\n",
    "                '            print(f\"  {i:2d}. {col}\")\\n',\n",
    "                \"        \\n\",\n",
    "                '        print(f\"\\\\n🔍 Sample Relationships:\")\\n',\n",
    "                \"        # Show key columns if they exist\\n\",\n",
    "                \"        key_cols = ['pronoun_text', 'clause_mate_count', 'most_recent_antecedent_distance', \\n\",\n",
    "                \"                   'givenness', 'animacy']\\n\",\n",
    "                \"        available_cols = [col for col in key_cols if col in df.columns]\\n\",\n",
    "                \"        \\n\",\n",
    "                \"        if available_cols:\\n\",\n",
    "                \"            sample_df = df[available_cols].head(3)\\n\",\n",
    "                \"            print(sample_df.to_string(index=False))\\n\",\n",
    "                \"        else:\\n\",\n",
    "                \"            print(df.head(3).to_string(index=False, max_cols=5))\\n\",\n",
    "                \"        \\n\",\n",
    "                \"        # Basic statistics\\n\",\n",
    "                '        print(f\"\\\\n📊 Quick Statistics:\")\\n',\n",
    "                '        print(f\"  - Total relationships: {len(df):,}\")\\n',\n",
    "                \"        if 'pronoun_text' in df.columns:\\n\",\n",
    "                \"            print(f\\\"  - Unique pronouns: {df['pronoun_text'].nunique()}\\\")\\n\",\n",
    "                \"        if 'clause_mate_count' in df.columns:\\n\",\n",
    "                \"            print(f\\\"  - Avg clause mates: {df['clause_mate_count'].mean():.1f}\\\")\\n\",\n",
    "                \"        if 'most_recent_antecedent_distance' in df.columns:\\n\",\n",
    "                \"            non_null = df['most_recent_antecedent_distance'].dropna()\\n\",\n",
    "                \"            if len(non_null) > 0:\\n\",\n",
    "                '                print(f\"  - Avg antecedent distance: {non_null.mean():.1f}\")\\n',\n",
    "                \"    \\n\",\n",
    "                \"    except Exception as e:\\n\",\n",
    "                '        print(f\"❌ Error reading output file: {e}\")\\n',\n",
    "                \"        \\n\",\n",
    "                \"else:\\n\",\n",
    "                '    print(\"📁 No output files found in any expected location:\")\\n',\n",
    "                \"    for location in output_locations:\\n\",\n",
    "                '        print(f\"  - {location} (exists: {location.exists()})\")\\n',\n",
    "                '    print(\"\\\\n💡 Run the analysis cell above first to generate output files\")\\n',\n",
    "                '    print(\"Or upload your own CSV results to data/output/\")',\n",
    "            ],\n",
    "        },\n",
    "        {\n",
    "            \"cell_type\": \"markdown\",\n",
    "            \"id\": \"e1ad3d98\",\n",
    "            \"metadata\": {},\n",
    "            \"source\": [\n",
    "                \"## Next Steps\\n\",\n",
    "                \"\\n\",\n",
    "                \"To use ClauseMate with your own data:\\n\",\n",
    "                \"\\n\",\n",
    "                \"1. **Prepare TSV files** in WebAnno TSV 3.3 format with coreference annotations\\n\",\n",
    "                \"2. **Upload to `data/input/gotofiles/`** directory\\n\",\n",
    "                \"3. **Run analysis** using `python -m src.main` or the analysis cell above\\n\",\n",
    "                \"4. **Examine results** in `data/output/` CSV files\\n\",\n",
    "                \"\\n\",\n",
    "                \"### Development Environment\\n\",\n",
    "                \"\\n\",\n",
    "                \"For local development, use:\\n\",\n",
    "                \"```bash\\n\",\n",
    "                \"# Install dependencies\\n\",\n",
    "                \"pip install -e .[dev]\\n\",\n",
    "                \"\\n\",\n",
    "                \"# Run with nox task runner\\n\",\n",
    "                \"nox                    # lint + test\\n\",\n",
    "                \"nox -s test           # pytest only\\n\",\n",
    "                \"nox -s format         # format code\\n\",\n",
    "                \"\\n\",\n",
    "                \"# Manual execution\\n\",\n",
    "                \"python -m src.main    # Phase 2 (preferred)\\n\",\n",
    "                \"python src/run_phase2.py\\n\",\n",
    "                \"```\\n\",\n",
    "                \"\\n\",\n",
    "                \"### Research Applications\\n\",\n",
    "                \"\\n\",\n",
    "                \"ClauseMate supports German linguistic research on:\\n\",\n",
    "                \"- Pronoun resolution strategies\\n\",\n",
    "                \"- Discourse coherence patterns  \\n\",\n",
    "                \"- Referential accessibility hierarchies\\n\",\n",
    "                \"- Cross-sentence coreference tracking\",\n",
    "            ],\n",
    "        },\n",
    "    ],\n",
    "    \"metadata\": {\n",
    "        \"kernelspec\": {\n",
    "            \"display_name\": \"Python 3\",\n",
    "            \"language\": \"python\",\n",
    "            \"name\": \"python3\",\n",
    "        },\n",
    "        \"language_info\": {\"name\": \"python\", \"version\": \"3.8+\"},\n",
    "    },\n",
    "    \"nbformat\": 4,\n",
    "    \"nbformat_minor\": 5,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa649a0",
   "metadata": {},
   "source": [
    "## Demo Analysis\n",
    "\n",
    "Let's run ClauseMate on the sample data to demonstrate its linguistic analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "36b49f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check available sample data\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"data/input/gotofiles\")\n",
    "if data_dir.exists():\n",
    "    tsv_files = list(data_dir.glob(\"*.tsv\"))\n",
    "    print(f\"Found {len(tsv_files)} TSV files for analysis:\")\n",
    "    for file in tsv_files[:3]:  # Show first 3\n",
    "        print(f\"  - {file.name}\")\n",
    "\n",
    "    if tsv_files:\n",
    "        sample_file = tsv_files[0]\n",
    "        print(f\"\\nUsing sample file: {sample_file.name}\")\n",
    "    else:\n",
    "        print(\"❌ No TSV files found in data/input/gotofiles/\")\n",
    "else:\n",
    "    print(\"❌ Data directory not found. Binder environment may need data setup.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "e7d4026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase 2 analysis (if data available)\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Ensure we're in the right directory\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == \"notebooks\" else current_dir\n",
    "\n",
    "# Check for data availability\n",
    "data_locations = [\n",
    "    project_root / \"data\" / \"input\" / \"gotofiles\",\n",
    "    Path(\"../data/input/gotofiles\"),\n",
    "    Path(\"data/input/gotofiles\"),\n",
    "]\n",
    "\n",
    "has_data = any(loc.exists() and list(loc.glob(\"*.tsv\")) for loc in data_locations)\n",
    "\n",
    "if has_data:\n",
    "    try:\n",
    "        # Change to project root for execution\n",
    "        original_cwd = os.getcwd()\n",
    "        os.chdir(project_root)\n",
    "        print(f\"Running analysis from: {os.getcwd()}\")\n",
    "\n",
    "        # Run the modular Phase 2 analysis\n",
    "        result = subprocess.run(\n",
    "            [sys.executable, \"-m\", \"src.main\"],\n",
    "            capture_output=True,\n",
    "            text=True,\n",
    "            timeout=60,\n",
    "        )\n",
    "\n",
    "        # Restore original directory\n",
    "        os.chdir(original_cwd)\n",
    "\n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ Phase 2 analysis completed successfully!\")\n",
    "            print(\"\\nOutput preview:\")\n",
    "            print(result.stdout[-500:] if result.stdout else \"No output captured\")\n",
    "        else:\n",
    "            print(f\"❌ Analysis failed with return code {result.returncode}\")\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "            if \"ModuleNotFoundError\" in result.stderr:\n",
    "                print(\"\\n💡 Try running the installation cell above first\")\n",
    "\n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"⏱️ Analysis timed out (60s limit in demo)\")\n",
    "        os.chdir(original_cwd)  # Restore directory even on timeout\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        os.chdir(original_cwd)  # Restore directory even on error\n",
    "else:\n",
    "    print(\"⚠️ Skipping analysis - no sample data available in Binder environment\")\n",
    "    print(\"To run full analysis, upload TSV files to data/input/gotofiles/\")\n",
    "    print(\"\\n💡 You can still explore the code structure and documentation!\")\n",
    "\n",
    "    # Show some basic information about the project\n",
    "    try:\n",
    "        os.chdir(project_root)\n",
    "        from src.config import TSVColumns\n",
    "\n",
    "        print(\"\\n📁 Project structure overview:\")\n",
    "        print(\"  - Config loaded successfully\")\n",
    "        print(\n",
    "            f\"  - TSV columns defined: {len([attr for attr in dir(TSVColumns) if not attr.startswith('_')])}\"\n",
    "        )\n",
    "        os.chdir(original_cwd)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load project info: {e}\")\n",
    "        os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee010205",
   "metadata": {},
   "source": [
    "## Understanding the Output\n",
    "\n",
    "ClauseMate generates CSV files with detailed linguistic relationships:\n",
    "\n",
    "### Key Columns:\n",
    "\n",
    "- **pronoun_text**: The critical pronoun being analyzed\n",
    "- **clause_mate_count**: Number of referential clause mates in same sentence  \n",
    "- **most_recent_antecedent_distance**: Linear distance to nearest mention in coreference chain\n",
    "- **first_antecedent_distance**: Distance to chain's initial mention\n",
    "- **givenness**: `neu` (first mention) vs `bekannt` (subsequent)\n",
    "- **animacy**: `anim` vs `inanim` coreference layers\n",
    "\n",
    "### Analysis Focus:\n",
    "\n",
    "The tool investigates linear position consistency of pronouns relative to clause mates in German discourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "id": "7fdf67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample output structure (if available)\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Try multiple possible output locations\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == \"notebooks\" else current_dir\n",
    "\n",
    "output_locations = [\n",
    "    project_root / \"data\" / \"output\",\n",
    "    current_dir / \"data\" / \"output\",\n",
    "    Path(\"../data/output\"),\n",
    "    Path(\"data/output\"),\n",
    "]\n",
    "\n",
    "output_files = []\n",
    "output_dir = None\n",
    "\n",
    "for location in output_locations:\n",
    "    if location.exists():\n",
    "        files = list(location.glob(\"*.csv\"))\n",
    "        if files:\n",
    "            output_files = files\n",
    "            output_dir = location\n",
    "            break\n",
    "\n",
    "if output_files:\n",
    "    latest_output = max(output_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"✓ Found output files in: {output_dir}\")\n",
    "    print(f\"Latest output file: {latest_output.name}\")\n",
    "\n",
    "    try:\n",
    "        # Show sample of results\n",
    "        df = pd.read_csv(latest_output)\n",
    "        print(\"\\n📊 Dataset Analysis:\")\n",
    "        print(f\"  - Shape: {df.shape}\")\n",
    "        print(f\"  - Columns: {len(df.columns)}\")\n",
    "\n",
    "        print(\"\\n📋 Column Names:\")\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "        print(\"\\n🔍 Sample Relationships:\")\n",
    "        # Show key columns if they exist\n",
    "        key_cols = [\n",
    "            \"pronoun_text\",\n",
    "            \"clause_mate_count\",\n",
    "            \"most_recent_antecedent_distance\",\n",
    "            \"givenness\",\n",
    "            \"animacy\",\n",
    "        ]\n",
    "        available_cols = [col for col in key_cols if col in df.columns]\n",
    "\n",
    "        if available_cols:\n",
    "            sample_df = df[available_cols].head(3)\n",
    "            print(sample_df.to_string(index=False))\n",
    "        else:\n",
    "            print(df.head(3).to_string(index=False, max_cols=5))\n",
    "\n",
    "        # Basic statistics\n",
    "        print(\"\\n📊 Quick Statistics:\")\n",
    "        print(f\"  - Total relationships: {len(df):,}\")\n",
    "        if \"pronoun_text\" in df.columns:\n",
    "            print(f\"  - Unique pronouns: {df['pronoun_text'].nunique()}\")\n",
    "        if \"clause_mate_count\" in df.columns:\n",
    "            print(f\"  - Avg clause mates: {df['clause_mate_count'].mean():.1f}\")\n",
    "        if \"most_recent_antecedent_distance\" in df.columns:\n",
    "            non_null = df[\"most_recent_antecedent_distance\"].dropna()\n",
    "            if len(non_null) > 0:\n",
    "                print(f\"  - Avg antecedent distance: {non_null.mean():.1f}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading output file: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"📁 No output files found in any expected location:\")\n",
    "    for location in output_locations:\n",
    "        print(f\"  - {location} (exists: {location.exists()})\")\n",
    "    print(\"\\n💡 Run the analysis cell above first to generate output files\")\n",
    "    print(\"Or upload your own CSV results to data/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad3d98",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "To use ClauseMate with your own data:\n",
    "\n",
    "1. **Prepare TSV files** in WebAnno TSV 3.3 format with coreference annotations\n",
    "2. **Upload to `data/input/gotofiles/`** directory\n",
    "3. **Run analysis** using `python -m src.main` or the analysis cell above\n",
    "4. **Examine results** in `data/output/` CSV files\n",
    "\n",
    "### Development Environment\n",
    "\n",
    "For local development, use:\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -e .[dev]\n",
    "\n",
    "# Run with nox task runner\n",
    "nox                    # lint + test\n",
    "nox -s test           # pytest only\n",
    "nox -s format         # format code\n",
    "\n",
    "# Manual execution\n",
    "python -m src.main    # Phase 2 (preferred)\n",
    "python src/run_phase2.py\n",
    "```\n",
    "\n",
    "### Research Applications\n",
    "\n",
    "ClauseMate supports German linguistic research on:\n",
    "- Pronoun resolution strategies\n",
    "- Discourse coherence patterns  \n",
    "- Referential accessibility hierarchies\n",
    "- Cross-sentence coreference tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
