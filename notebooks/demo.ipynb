{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893dbcea",
   "metadata": {},
   "source": [
    "# ClauseMate: German Clause Mate Analysis Demo\n",
    "\n",
    "This notebook demonstrates ClauseMate's capabilities for analyzing pronoun-clause mate relationships in German linguistic data.\n",
    "\n",
    "## What is ClauseMate?\n",
    "ClauseMate is a research tool that investigates whether pronouns appear at more consistent linear positions when clause mates are present vs. absent in German discourse.\n",
    "\n",
    "### Key Features:\n",
    "- **94.4% antecedent detection** across sentence boundaries\n",
    "- **Cross-sentence coreference tracking** with chain analysis  \n",
    "- **German-specific pronoun classification** (3rd person, D-pronouns, demonstratives)\n",
    "- **WebAnno TSV 3.3 format** support for linguistic annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a556195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ClauseMate in Binder environment\n",
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Change to project root directory (parent of notebooks/)\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(f\"Project root: {project_root}\")\n",
    "\n",
    "# Check if we have the project files\n",
    "required_files = ['pyproject.toml', 'src', 'requirements.txt']\n",
    "missing_files = [f for f in required_files if not os.path.exists(os.path.join(project_root, f))]\n",
    "\n",
    "if missing_files:\n",
    "    print(f\"❌ Missing required files in {project_root}: {missing_files}\")\n",
    "    print(\"Make sure you're running in a ClauseMate repository\")\n",
    "else:\n",
    "    # Change to project root and install\n",
    "    os.chdir(project_root)\n",
    "    print(f\"Changed to project root: {os.getcwd()}\")\n",
    "    \n",
    "    try:\n",
    "        # Install the package in editable mode\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-e\", \".\"])\n",
    "        print(\"✓ ClauseMate installed successfully!\")\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"❌ Installation failed: {e}\")\n",
    "        print(\"Trying alternative installation...\")\n",
    "        try:\n",
    "            # Try installing requirements directly\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-r\", \"requirements.txt\"])\n",
    "            print(\"✓ Requirements installed successfully!\")\n",
    "        except subprocess.CalledProcessError as e2:\n",
    "            print(f\"❌ Alternative installation also failed: {e2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d51d1c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ClauseMate modules\n",
    "try:\n",
    "    from src.main import main\n",
    "    from src.config import FilePaths, TSVColumns\n",
    "    from src.data.models import SentenceContext, Token\n",
    "    print(\"✓ ClauseMate modules imported successfully!\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"Make sure you're running from the project root directory.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa649a0",
   "metadata": {},
   "source": [
    "## Demo Analysis\n",
    "\n",
    "Let's run ClauseMate on the sample data to demonstrate its linguistic analysis capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b49f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"893dbcea\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# ClauseMate: German Clause Mate Analysis Demo\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook demonstrates ClauseMate's capabilities for analyzing pronoun-clause mate relationships in German linguistic data.\\n\",\n",
    "    \"\\n\",\n",
    "    \"## What is ClauseMate?\\n\",\n",
    "    \"ClauseMate is a research tool that investigates whether pronouns appear at more consistent linear positions when clause mates are present vs. absent in German discourse.\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Features:\\n\",\n",
    "    \"- **94.4% antecedent detection** across sentence boundaries\\n\",\n",
    "    \"- **Cross-sentence coreference tracking** with chain analysis  \\n\",\n",
    "    \"- **German-specific pronoun classification** (3rd person, D-pronouns, demonstratives)\\n\",\n",
    "    \"- **WebAnno TSV 3.3 format** support for linguistic annotations\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"6a556195\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Install ClauseMate in Binder environment\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"import subprocess\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Install the package in editable mode\\n\",\n",
    "    \"subprocess.check_call([sys.executable, \\\"-m\\\", \\\"pip\\\", \\\"install\\\", \\\"-e\\\", \\\".\\\"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"✓ ClauseMate installed successfully!\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"8d51d1c4\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import ClauseMate modules\\n\",\n",
    "    \"try:\\n\",\n",
    "    \"    from src.main import main\\n\",\n",
    "    \"    from src.config import FilePaths, TSVColumns\\n\",\n",
    "    \"    from src.data.models import SentenceContext, Token\\n\",\n",
    "    \"    print(\\\"✓ ClauseMate modules imported successfully!\\\")\\n\",\n",
    "    \"except ImportError as e:\\n\",\n",
    "    \"    print(f\\\"❌ Import error: {e}\\\")\\n\",\n",
    "    \"    print(\\\"Make sure you're running from the project root directory.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"0fa649a0\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Demo Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"Let's run ClauseMate on the sample data to demonstrate its linguistic analysis capabilities.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"36b49f89\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Check available sample data\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import os\\n\",\n",
    "    \"\\n\",\n",
    "    \"data_dir = Path(\\\"data/input/gotofiles\\\")\\n\",\n",
    "    \"if data_dir.exists():\\n\",\n",
    "    \"    tsv_files = list(data_dir.glob(\\\"*.tsv\\\"))\\n\",\n",
    "    \"    print(f\\\"Found {len(tsv_files)} TSV files for analysis:\\\")\\n\",\n",
    "    \"    for file in tsv_files[:3]:  # Show first 3\\n\",\n",
    "    \"        print(f\\\"  - {file.name}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if tsv_files:\\n\",\n",
    "    \"        sample_file = tsv_files[0]\\n\",\n",
    "    \"        print(f\\\"\\\\nUsing sample file: {sample_file.name}\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(\\\"❌ No TSV files found in data/input/gotofiles/\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"❌ Data directory not found. Binder environment may need data setup.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"e7d4026b\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Run Phase 2 analysis (if data available)\\n\",\n",
    "    \"import subprocess\\n\",\n",
    "    \"import sys\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"\\n\",\n",
    "    \"if Path(\\\"data/input/gotofiles\\\").exists() and list(Path(\\\"data/input/gotofiles\\\").glob(\\\"*.tsv\\\")):\\n\",\n",
    "    \"    try:\\n\",\n",
    "    \"        # Run the modular Phase 2 analysis\\n\",\n",
    "    \"        result = subprocess.run([\\n\",\n",
    "    \"            sys.executable, \\\"-m\\\", \\\"src.main\\\"\\n\",\n",
    "    \"        ], capture_output=True, text=True, timeout=60)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        if result.returncode == 0:\\n\",\n",
    "    \"            print(\\\"✓ Phase 2 analysis completed successfully!\\\")\\n\",\n",
    "    \"            print(\\\"\\\\nOutput preview:\\\")\\n\",\n",
    "    \"            print(result.stdout[-500:])  # Last 500 chars\\n\",\n",
    "    \"        else:\\n\",\n",
    "    \"            print(f\\\"❌ Analysis failed with return code {result.returncode}\\\")\\n\",\n",
    "    \"            print(f\\\"Error: {result.stderr}\\\")\\n\",\n",
    "    \"            \\n\",\n",
    "    \"    except subprocess.TimeoutExpired:\\n\",\n",
    "    \"        print(\\\"⏱️ Analysis timed out (60s limit in demo)\\\")\\n\",\n",
    "    \"    except Exception as e:\\n\",\n",
    "    \"        print(f\\\"❌ Unexpected error: {e}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"⚠️ Skipping analysis - no sample data available in Binder environment\\\")\\n\",\n",
    "    \"    print(\\\"To run full analysis, upload TSV files to data/input/gotofiles/\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"ee010205\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Understanding the Output\\n\",\n",
    "    \"\\n\",\n",
    "    \"ClauseMate generates CSV files with detailed linguistic relationships:\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Key Columns:\\n\",\n",
    "    \"- **pronoun_text**: The critical pronoun being analyzed\\n\",\n",
    "    \"- **clause_mate_count**: Number of referential clause mates in same sentence  \\n\",\n",
    "    \"- **most_recent_antecedent_distance**: Linear distance to nearest mention in coreference chain\\n\",\n",
    "    \"- **first_antecedent_distance**: Distance to chain's initial mention\\n\",\n",
    "    \"- **givenness**: `neu` (first mention) vs `bekannt` (subsequent)\\n\",\n",
    "    \"- **animacy**: `anim` vs `inanim` coreference layers\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Analysis Focus:\\n\",\n",
    "    \"The tool investigates linear position consistency of pronouns relative to clause mates in German discourse.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": 0,\n",
    "   \"id\": \"7fdf67d1\",\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Show sample output structure (if available)\\n\",\n",
    "    \"from pathlib import Path\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"\\n\",\n",
    "    \"output_files = list(Path(\\\"data/output\\\").glob(\\\"*.csv\\\")) if Path(\\\"data/output\\\").exists() else []\\n\",\n",
    "    \"\\n\",\n",
    "    \"if output_files:\\n\",\n",
    "    \"    latest_output = max(output_files, key=lambda p: p.stat().st_mtime)\\n\",\n",
    "    \"    print(f\\\"Latest output file: {latest_output.name}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Show sample of results\\n\",\n",
    "    \"    df = pd.read_csv(latest_output)\\n\",\n",
    "    \"    print(f\\\"\\\\nDataset shape: {df.shape}\\\")\\n\",\n",
    "    \"    print(f\\\"\\\\nColumns: {list(df.columns)}\\\")\\n\",\n",
    "    \"    print(f\\\"\\\\nSample relationships:\\\")\\n\",\n",
    "    \"    print(df.head(3).to_string(index=False))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Basic statistics\\n\",\n",
    "    \"    print(f\\\"\\\\n📊 Quick Statistics:\\\")\\n\",\n",
    "    \"    print(f\\\"  - Total relationships: {len(df)}\\\")\\n\",\n",
    "    \"    print(f\\\"  - Unique pronouns: {df['pronoun_text'].nunique()}\\\")\\n\",\n",
    "    \"    print(f\\\"  - Avg clause mates: {df['clause_mate_count'].mean():.1f}\\\")\\n\",\n",
    "    \"    if 'most_recent_antecedent_distance' in df.columns:\\n\",\n",
    "    \"        print(f\\\"  - Avg antecedent distance: {df['most_recent_antecedent_distance'].mean():.1f}\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"No output files found. Run the analysis cell above first.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"id\": \"e1ad3d98\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## Next Steps\\n\",\n",
    "    \"\\n\",\n",
    "    \"To use ClauseMate with your own data:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Prepare TSV files** in WebAnno TSV 3.3 format with coreference annotations\\n\",\n",
    "    \"2. **Upload to `data/input/gotofiles/`** directory\\n\",\n",
    "    \"3. **Run analysis** using `python -m src.main` or the analysis cell above\\n\",\n",
    "    \"4. **Examine results** in `data/output/` CSV files\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Development Environment\\n\",\n",
    "    \"For local development, use:\\n\",\n",
    "    \"```bash\\n\",\n",
    "    \"# Install dependencies\\n\",\n",
    "    \"pip install -e .[dev]\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Run with nox task runner\\n\",\n",
    "    \"nox                    # lint + test\\n\",\n",
    "    \"nox -s test           # pytest only\\n\",\n",
    "    \"nox -s format         # format code\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Manual execution\\n\",\n",
    "    \"python -m src.main    # Phase 2 (preferred)\\n\",\n",
    "    \"python src/run_phase2.py\\n\",\n",
    "    \"```\\n\",\n",
    "    \"\\n\",\n",
    "    \"### Research Applications\\n\",\n",
    "    \"ClauseMate supports German linguistic research on:\\n\",\n",
    "    \"- Pronoun resolution strategies\\n\",\n",
    "    \"- Discourse coherence patterns  \\n\",\n",
    "    \"- Referential accessibility hierarchies\\n\",\n",
    "    \"- Cross-sentence coreference tracking\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"name\": \"python\",\n",
    "   \"version\": \"3.8+\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 5\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d4026b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Phase 2 analysis (if data available)\n",
    "import subprocess\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Ensure we're in the right directory\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "\n",
    "# Check for data availability\n",
    "data_locations = [\n",
    "    project_root / \"data\" / \"input\" / \"gotofiles\",\n",
    "    Path(\"../data/input/gotofiles\"),\n",
    "    Path(\"data/input/gotofiles\")\n",
    "]\n",
    "\n",
    "has_data = any(loc.exists() and list(loc.glob(\"*.tsv\")) for loc in data_locations)\n",
    "\n",
    "if has_data:\n",
    "    try:\n",
    "        # Change to project root for execution\n",
    "        original_cwd = os.getcwd()\n",
    "        os.chdir(project_root)\n",
    "        print(f\"Running analysis from: {os.getcwd()}\")\n",
    "        \n",
    "        # Run the modular Phase 2 analysis\n",
    "        result = subprocess.run([\n",
    "            sys.executable, \"-m\", \"src.main\"\n",
    "        ], capture_output=True, text=True, timeout=60)\n",
    "        \n",
    "        # Restore original directory\n",
    "        os.chdir(original_cwd)\n",
    "        \n",
    "        if result.returncode == 0:\n",
    "            print(\"✓ Phase 2 analysis completed successfully!\")\n",
    "            print(\"\\nOutput preview:\")\n",
    "            print(result.stdout[-500:] if result.stdout else \"No output captured\")\n",
    "        else:\n",
    "            print(f\"❌ Analysis failed with return code {result.returncode}\")\n",
    "            print(f\"Error: {result.stderr}\")\n",
    "            if \"ModuleNotFoundError\" in result.stderr:\n",
    "                print(\"\\n💡 Try running the installation cell above first\")\n",
    "            \n",
    "    except subprocess.TimeoutExpired:\n",
    "        print(\"⏱️ Analysis timed out (60s limit in demo)\")\n",
    "        os.chdir(original_cwd)  # Restore directory even on timeout\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Unexpected error: {e}\")\n",
    "        os.chdir(original_cwd)  # Restore directory even on error\n",
    "else:\n",
    "    print(\"⚠️ Skipping analysis - no sample data available in Binder environment\")\n",
    "    print(\"To run full analysis, upload TSV files to data/input/gotofiles/\")\n",
    "    print(\"\\n💡 You can still explore the code structure and documentation!\")\n",
    "    \n",
    "    # Show some basic information about the project\n",
    "    try:\n",
    "        os.chdir(project_root)\n",
    "        from src.config import FilePaths, TSVColumns\n",
    "        print(f\"\\n📁 Project structure overview:\")\n",
    "        print(f\"  - Config loaded successfully\")\n",
    "        print(f\"  - TSV columns defined: {len([attr for attr in dir(TSVColumns) if not attr.startswith('_')])}\")\n",
    "        os.chdir(original_cwd)\n",
    "    except Exception as e:\n",
    "        print(f\"Could not load project info: {e}\")\n",
    "        os.chdir(original_cwd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee010205",
   "metadata": {},
   "source": [
    "## Understanding the Output\n",
    "\n",
    "ClauseMate generates CSV files with detailed linguistic relationships:\n",
    "\n",
    "### Key Columns:\n",
    "- **pronoun_text**: The critical pronoun being analyzed\n",
    "- **clause_mate_count**: Number of referential clause mates in same sentence  \n",
    "- **most_recent_antecedent_distance**: Linear distance to nearest mention in coreference chain\n",
    "- **first_antecedent_distance**: Distance to chain's initial mention\n",
    "- **givenness**: `neu` (first mention) vs `bekannt` (subsequent)\n",
    "- **animacy**: `anim` vs `inanim` coreference layers\n",
    "\n",
    "### Analysis Focus:\n",
    "The tool investigates linear position consistency of pronouns relative to clause mates in German discourse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdf67d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show sample output structure (if available)\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Try multiple possible output locations\n",
    "current_dir = Path.cwd()\n",
    "project_root = current_dir.parent if current_dir.name == 'notebooks' else current_dir\n",
    "\n",
    "output_locations = [\n",
    "    project_root / \"data\" / \"output\",\n",
    "    current_dir / \"data\" / \"output\",\n",
    "    Path(\"../data/output\"),\n",
    "    Path(\"data/output\")\n",
    "]\n",
    "\n",
    "output_files = []\n",
    "output_dir = None\n",
    "\n",
    "for location in output_locations:\n",
    "    if location.exists():\n",
    "        files = list(location.glob(\"*.csv\"))\n",
    "        if files:\n",
    "            output_files = files\n",
    "            output_dir = location\n",
    "            break\n",
    "\n",
    "if output_files:\n",
    "    latest_output = max(output_files, key=lambda p: p.stat().st_mtime)\n",
    "    print(f\"✓ Found output files in: {output_dir}\")\n",
    "    print(f\"Latest output file: {latest_output.name}\")\n",
    "    \n",
    "    try:\n",
    "        # Show sample of results\n",
    "        df = pd.read_csv(latest_output)\n",
    "        print(f\"\\n📊 Dataset Analysis:\")\n",
    "        print(f\"  - Shape: {df.shape}\")\n",
    "        print(f\"  - Columns: {len(df.columns)}\")\n",
    "        \n",
    "        print(f\"\\n📋 Column Names:\")\n",
    "        for i, col in enumerate(df.columns, 1):\n",
    "            print(f\"  {i:2d}. {col}\")\n",
    "        \n",
    "        print(f\"\\n🔍 Sample Relationships:\")\n",
    "        # Show key columns if they exist\n",
    "        key_cols = ['pronoun_text', 'clause_mate_count', 'most_recent_antecedent_distance', \n",
    "                   'givenness', 'animacy']\n",
    "        available_cols = [col for col in key_cols if col in df.columns]\n",
    "        \n",
    "        if available_cols:\n",
    "            sample_df = df[available_cols].head(3)\n",
    "            print(sample_df.to_string(index=False))\n",
    "        else:\n",
    "            print(df.head(3).to_string(index=False, max_cols=5))\n",
    "        \n",
    "        # Basic statistics\n",
    "        print(f\"\\n\udcc8 Quick Statistics:\")\n",
    "        print(f\"  - Total relationships: {len(df):,}\")\n",
    "        if 'pronoun_text' in df.columns:\n",
    "            print(f\"  - Unique pronouns: {df['pronoun_text'].nunique()}\")\n",
    "        if 'clause_mate_count' in df.columns:\n",
    "            print(f\"  - Avg clause mates: {df['clause_mate_count'].mean():.1f}\")\n",
    "        if 'most_recent_antecedent_distance' in df.columns:\n",
    "            non_null = df['most_recent_antecedent_distance'].dropna()\n",
    "            if len(non_null) > 0:\n",
    "                print(f\"  - Avg antecedent distance: {non_null.mean():.1f}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error reading output file: {e}\")\n",
    "        \n",
    "else:\n",
    "    print(\"📁 No output files found in any expected location:\")\n",
    "    for location in output_locations:\n",
    "        print(f\"  - {location} (exists: {location.exists()})\")\n",
    "    print(\"\\n💡 Run the analysis cell above first to generate output files\")\n",
    "    print(\"Or upload your own CSV results to data/output/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ad3d98",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "To use ClauseMate with your own data:\n",
    "\n",
    "1. **Prepare TSV files** in WebAnno TSV 3.3 format with coreference annotations\n",
    "2. **Upload to `data/input/gotofiles/`** directory\n",
    "3. **Run analysis** using `python -m src.main` or the analysis cell above\n",
    "4. **Examine results** in `data/output/` CSV files\n",
    "\n",
    "### Development Environment\n",
    "For local development, use:\n",
    "```bash\n",
    "# Install dependencies\n",
    "pip install -e .[dev]\n",
    "\n",
    "# Run with nox task runner\n",
    "nox                    # lint + test\n",
    "nox -s test           # pytest only\n",
    "nox -s format         # format code\n",
    "\n",
    "# Manual execution\n",
    "python -m src.main    # Phase 2 (preferred)\n",
    "python src/run_phase2.py\n",
    "```\n",
    "\n",
    "### Research Applications\n",
    "ClauseMate supports German linguistic research on:\n",
    "- Pronoun resolution strategies\n",
    "- Discourse coherence patterns  \n",
    "- Referential accessibility hierarchies\n",
    "- Cross-sentence coreference tracking"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
